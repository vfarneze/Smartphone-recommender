{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests version: 2.22.0\n"
     ]
    }
   ],
   "source": [
    "print('requests version:', requests.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping www.americanas.com.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main search: https://www.americanas.com.br/.../smartphone/{manufacturer}/pagina-2?ornenacao={orderby}\n",
    "\n",
    "Possible manufacturers: samsung-galaxy, iphone, motorola, zenfone, lg, alcatel, quantum, quantum, q-touch, huawei, zte, sony-xperia, lenovo, meizu, lumia, xiaomi, yezz and multilaser.\n",
    "\n",
    "THIS WEBSITE ONLY SHOWS 24 items PER PAGE! The stragegy is to look for the number of products on\n",
    "the first page (the website shows the number of products in the query) and divide this number by\n",
    "24, to know how many pages to search, per brand..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best aproach until now was:\n",
    "* 1- create 3 functions, for each operating system. The website from americanas.com let you chain the operation systems of the products (windows, ios, android, etc), so the strategy was to create 3 massive links, for each function, and iterate over the pages on those links. Hopefully the majority of the smartphones will be found.\n",
    "* 2- For each operational system, the main code works this way: \n",
    "> - soup the first url, then look the amount of products.\n",
    "> - the number of products divided by 24 and rounded up will give the amount of pages.\n",
    "> - Iterate over the number of pages (from 2 to max), get soups, and store information in dataframes (page, description of product, crude link for the product, link for the product, and a timestamp)\n",
    "> - At the end concatenate all dataframes together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_number_of_pages(soup):\n",
    "    \"\"\"This function looks for the number or products on the page query and returns the number of pages.\n",
    "    The number of pages will help iterage over the brand pages\"\"\"\n",
    "    nproducts = soup.find_all('div', attrs={'class': \"form-group display-sm-inline-block\"})[0].text.split(' ')[0]\n",
    "    if '.' in nproducts:\n",
    "        nproducts = nproducts.split('.')[0] + nproducts.split('.')[1]\n",
    "    print(f'number of products are: {nproducts}')\n",
    "    npages = str(int(nproducts)/24).split('.')[0]\n",
    "    return int(npages) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_products_data_from_soup(soup, page):\n",
    "    \"\"\"\n",
    "    This function receives a soup from americanas.com and returns a dataframe with infos\n",
    "    from the 24 products.\n",
    "    \"\"\"\n",
    "    products = soup.find_all('div', attrs={'class':\"RippleContainer-sc-1rpenp9-0 dMCfqq\"})\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for product in products:\n",
    "        texto_produto = product.text\n",
    "        link_produto_crude = product.find_all('a')[0]['href']\n",
    "        link_produto = 'https://www.americanas.com.br' + link_produto_crude.split('?')[0]\n",
    "\n",
    "        minidf = pd.DataFrame({'page': page,\n",
    "                                'texto_produto':texto_produto,\n",
    "                                'link_produto_crude':link_produto_crude,\n",
    "                                'link_produto':link_produto,\n",
    "                                'timestamp': datetime.now()}, index=[0])\n",
    "\n",
    "        results = pd.concat([results,minidf])\n",
    "    \n",
    "    return results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "def get_soup_from_url(url):\n",
    "    \"\"\"This function gets an url and returns a bs4 soup\"\"\"\n",
    "    \n",
    "    headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "        }\n",
    "    response = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def save_to_csv(dataframe, name):\n",
    "    \"\"\"This function takes a dataframe and stores it with a yyyy-mm-dd-hh.csv stamp,\n",
    "    with cp1252 enconding\"\"\"\n",
    "    t = datetime.now()\n",
    "    time = f'{str(t.year)}y-{str(t.month)}m-{str(t.day)}d-{str(t.hour)}h'\n",
    "    dataframe.to_csv('storage/' + name + time + '.csv', encoding='cp1252')\n",
    "    print(name + ' saved at: ' + time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOS system functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ios_url(page):\n",
    "    \"\"\"\n",
    "    This function gets the page number and returns the URL for the IOS\n",
    "    devices from americanas.com.\n",
    "    \"\"\"\n",
    "    ios0 = 'https://www.americanas.com.br/categoria/celulares-e-smartphones/smartphone/f'\n",
    "    ios1 = '/sistema-operacional-ios'\n",
    "    ios2 = '/sistema-operacional-ios%2010'\n",
    "    ios3 = '/sistema-operacional-ios%2011'\n",
    "    ios4 = '/sistema-operacional-ios%207'\n",
    "    ios5 = '/sistema-operacional-ios%208'\n",
    "    ios6 = '/sistema-operacional-ios%209'\n",
    "    ios7 = '/sistema-operacional-iphone%20ios'\n",
    "    if page == 1:\n",
    "        pag = ''\n",
    "    else:\n",
    "        pag = f'/pagina-{page}'\n",
    "    end = '?ordenacao=higherPrice'\n",
    "\n",
    "    return ios0 + ios1 + ios2 + ios3 + ios4 + ios5 + ios6 + ios7 + pag + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_ios_results():\n",
    "    soup = get_soup_from_url(ios_url(1))\n",
    "\n",
    "    npages = get_number_of_pages(soup)\n",
    "\n",
    "    ios_results = extract_products_data_from_soup(soup, page=1)\n",
    "\n",
    "    for page in tqdm(np.arange(2,npages+1)):\n",
    "        soup = get_soup_from_url(ios_url(page))\n",
    "        minidf = extract_products_data_from_soup(soup, page=1)\n",
    "        ios_results = pd.concat([ios_results,minidf])\n",
    "\n",
    "    save_to_csv(ios_results, 'americanas_IOS_raw')\n",
    "    \n",
    "    return ios_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Android functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def android_url(page):\n",
    "    \"\"\"\n",
    "    This function gets the page number and returns the URL for the Android devices from americanas.com.\n",
    "    \"\"\"\n",
    "    and0 = 'https://www.americanas.com.br/categoria/celulares-e-smartphones/smartphone/f'\n",
    "    and00 = '/sistema-operacional-android/'\n",
    "    and1 = '/sistema-operacional-android%20(miui).%20sistema%20operacional%20devidamente%20personalizado%20e%20otimizado%20pela%20xiaomi%20com%20funcionalidades%20exclusivas.'\n",
    "    and2 = '/sistema-operacional-android%204'\n",
    "    and3 = '/sistema-operacional-android%205'\n",
    "    and4 = '/sistema-operacional-android%205.0%20lollipop'\n",
    "    and5 = '/sistema-operacional-android%205.0.1%20lollipop'\n",
    "    and6 = '/sistema-operacional-android%205.0.2%20lollipop'\n",
    "    and7 = '/sistema-operacional-android%205.1%20asuszenuilollipop'\n",
    "    and8 = '/sistema-operacional-android%205.1%20lollipop'\n",
    "    and9 = '/sistema-operacional-android%205.1.1%20lollipop'\n",
    "    and10 = '/sistema-operacional-android%206'\n",
    "    and11 = '/sistema-operacional-android%207'\n",
    "    and12 = '/sistema-operacional-android%207.1.1%20nougat'\n",
    "    and13 = '/sistema-operacional-android%208.0'\n",
    "    and14 = '/sistema-operacional-android%208.0%20oreo'\n",
    "    and15 = '/sistema-operacional-android%208.1'\n",
    "    and16 = '/sistema-operacional-android%208.1%20(versao%20go)'\n",
    "    and17 = '/sistema-operacional-android%208.1%20oreo'\n",
    "    and18 = '/sistema-operacional-android%20go'\n",
    "\n",
    "    if page == 1:\n",
    "        pag = ''\n",
    "    else:\n",
    "        pag = f'/pagina-{page}?'\n",
    "    end = '?ordenacao=higherPrice'\n",
    "    \n",
    "    return and0 + and00 + and1 + and2 + and3 + and4 + and5 + and6 + and7 +\\\n",
    "            and8 + and9 + and10 + and11 + and12 + and13 + and14 +\\\n",
    "            and15 + and16 + and17 + and18 + pag + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_android_results():\n",
    "    soup = get_soup_from_url(android_url(1))\n",
    "\n",
    "    npages = get_number_of_pages(soup)\n",
    "\n",
    "    android_results = extract_products_data_from_soup(soup, page=1)\n",
    "\n",
    "    for page in tqdm(np.arange(2,npages+1)):\n",
    "        soup = get_soup_from_url(android_url(page))\n",
    "        minidf = extract_products_data_from_soup(soup, page=1)\n",
    "        android_results = pd.concat([android_results,minidf])\n",
    "\n",
    "    save_to_csv(android_results, 'americanas_Android_raw')\n",
    "    return android_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows and Others functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def windows_url(page):\n",
    "    \"\"\"\n",
    "    This function gets the page number and returns the URL for the windows and other devices from americanas.com.\n",
    "    \"\"\"\n",
    "    win0 = 'https://www.americanas.com.br/categoria/celulares-e-smartphones/smartphone/f'\n",
    "    win1 = '/sistema-operacional-outros'\n",
    "    win2 = '/sistema-operacional-proprietary%20os'\n",
    "    win3 = '/sistema-operacional-windows'\n",
    "    win4 = '/sistema-operacional-windows%20phone'\n",
    "\n",
    "    if page == 1:\n",
    "        pag = ''\n",
    "    else:\n",
    "        pag = f'/pagina-{page}?'\n",
    "    end = '?ordenacao=higherPrice'\n",
    "    \n",
    "    return win0 + win1 + win2 + win3 + win4 + pag + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_windows_results():\n",
    "\n",
    "    soup = get_soup_from_url(windows_url(1))\n",
    "\n",
    "    npages = get_number_of_pages(soup)\n",
    "\n",
    "    windows_results = extract_products_data_from_soup(soup, page=1)\n",
    "\n",
    "    for page in tqdm(np.arange(2,npages+1)):\n",
    "        soup = get_soup_from_url(windows_url(page))\n",
    "        minidf = extract_products_data_from_soup(soup, page=1)\n",
    "        android_results = pd.concat([windows_results,minidf])\n",
    "\n",
    "    save_to_csv(windows_results, 'americanas_windows_raw')\n",
    "    return windows_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of products are: 406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:25<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "americanas_IOS_raw saved at: 2020y-5m-7d-11h\n",
      "number of products are: 1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [04:06<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "americanas_Android_raw saved at: 2020y-5m-7d-11h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of products are: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "americanas_windows_raw saved at: 2020y-5m-7d-11h\n",
      "americanas_raw saved at: 2020y-5m-7d-11h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ios = generate_ios_results()\n",
    "android = generate_android_results()\n",
    "windows = generate_windows_results()\n",
    "americanas = pd.concat([ios,android,windows]).reset_index(drop=True)\n",
    "print(f'{americanas.shape[0]} produtos foram cadastrados!')\n",
    "save_to_csv(americanas, 'americanas_raw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
